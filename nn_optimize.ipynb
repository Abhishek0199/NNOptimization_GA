{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600517012801",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fetch the dataset from the csv using Pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#list of columns to be read from the csv for the data part\n",
    "# names = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"] \n",
    "\n",
    "dataset = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# Get the X\n",
    "X = dataset.iloc[:, 0:8].values\n",
    "\n",
    "#Get the labels\n",
    "Y = dataset.iloc[:, 8].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to convert the binary array into the corresponding decimal value using basic binary to decimal conversion. This is used to convert the af, hd1 and hd2 binary arrays to their corresponding decimal value\n",
    "def binary_to_decimal(bin_str):\n",
    "    dec_value = 0\n",
    "\n",
    "    num_bits = 0 #stores the position of bit from right\n",
    "    for bit in reversed(bin_str):\n",
    "        if bit == 1:\n",
    "            dec_value = dec_value + 2**num_bits\n",
    "        num_bits = num_bits + 1\n",
    "    \n",
    "    return dec_value #return the decimal value of the binary array\n",
    "\n",
    "# binary_to_decimal([0, 1, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to convert the value of alpha from array to the float value using binary to decimal conversion with bits treated as after decimal.\n",
    "def alpha_value(alpha):\n",
    "    #Stores the value of the learning rate in form of float\n",
    "    lr = 0.0\n",
    "\n",
    "    num_bits = 1\n",
    "    for i in range(len(alpha)):\n",
    "        #if the value of alpha at position i is 1 then we can add the value to lr\n",
    "        if alpha[i] == 1:\n",
    "            lr = lr + (1/2**num_bits) #add the value as 1/2^r where r is the bit position from left\n",
    "        num_bits = num_bits + 1\n",
    "\n",
    "    return lr #return the value of the learning rate\n",
    "\n",
    "# alpha_value([1, 0, 0, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This function is used to split the chromosome into the lying components of the neural network. In general we will work on the chromosome as a whole, however for verifying and training we need the values of each component separately and thus, this returns all the components in form of list.\n",
    "def split_chromosome(chromosome):\n",
    "    #Length of the chromosome has to be 16\n",
    "    assert len(chromosome) == 16\n",
    "\n",
    "    alpha = chromosome[0:4] #alpha is the first 4 bits\n",
    "    af = chromosome[4:6] #activation function is the next 2 bits\n",
    "    hd1 = chromosome[6:11] #number of hidden neurons in hidden layer 1 are the next 5 bits\n",
    "    hd2 = chromosome[11:16] #number of hidden neurons in hidden layer 2 are the next 5 bits\n",
    "\n",
    "    return (alpha, af, hd1, hd2)\n",
    "\n",
    "# print(split_chromosome([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to verify if the chromosome is valid or not. Returns true if valid, ekse false\n",
    "def verify_chromosome(chromo):\n",
    "    #split the chromosome into the integer arrays for each component\n",
    "    lr, af, hd1, hd2 = split_chromosome(chromo)\n",
    "\n",
    "    #check the values of the components if satisfy the constraints.\n",
    "    if alpha_value(lr) <= 0.0 or alpha_value(lr) >= 1.0:\n",
    "        return False\n",
    "    if binary_to_decimal(hd1) < 2:\n",
    "        return False\n",
    "    return True   #return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_chromosome is responsible to generate a chromosome and sends true if the chromosome generated is a valid one (satisfies all the constraints) and false in case of invalid chromosome\n",
    "def generate_chromosome(chromo_size):\n",
    "    #generate the chromosome of size chromo_size with values between 0 or 1\n",
    "    chromo = [np.random.randint(0, 2) for i in range(chromo_size)]\n",
    "\n",
    "    flag = verify_chromosome(chromo)\n",
    "\n",
    "    if flag:\n",
    "        return (chromo, True)\n",
    "    return (chromo, False)\n",
    "\n",
    "# generate_chromosome(16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initial_Population is used to generate the initial population of size 30. The pop is generated by randomly setting each value as 0 or 1 for the 16 indices. We will also verify the value of each component simultaneously to ensure that all the components are in the constrains to be satisfied. This function returns a list of list of size (pop_size, chromosome_size)\n",
    "def Initial_Population(pop_size, chromo_size):\n",
    "\n",
    "    #Initialize the population variable as a list of lists of size (30, 16)\n",
    "    pop = [[int() for i in range(chromo_size)] for j in range(pop_size)] \n",
    "\n",
    "    for i in range(pop_size):\n",
    "        #set the flag as false\n",
    "        flag = False\n",
    "\n",
    "        while not flag:\n",
    "            #get the values of the chromosome and flag from the function. If flag becomes true then the while loop stops and generates no more chromosomes.\n",
    "            pop[i], flag = generate_chromosome(chromo_size)\n",
    "    \n",
    "    return pop\n",
    "\n",
    "# Initial_Population(30, 16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for mapping the activation functions to the integer values\n",
    "int_af = {}\n",
    "\n",
    "int_af[0] = 'relu'\n",
    "int_af[1] = 'tanh'\n",
    "int_af[2] = 'sigmoid'\n",
    "int_af[3] = 'selu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Params\n",
    "\n",
    "#population size\n",
    "pop_size = 30\n",
    "\n",
    "#chromosome size\n",
    "chromo_size = 16\n",
    "\n",
    "#number of generations\n",
    "num_gen = 100\n",
    "\n",
    "#number of epochs for training\n",
    "num_epochs = 25\n",
    "\n",
    "#batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import the dependencies\n",
    "import keras\n",
    "from tensorflow.keras.initializers import GlorotUniform as glorot_uniform\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "#Train_model is used to train the model and return the loss after the training. For this, first convert the input chromosome into it's components by splitting the chromosome into the values and then constructing the neural network and then training for the number of epochs = 25.\n",
    "input_shape = X.shape #input shape\n",
    "classes = 1 #consist of only 1 label true or false\n",
    "\n",
    "def Train_model(chromo):\n",
    "\n",
    "\n",
    "    #split the chromosome into the components\n",
    "    lr, af, hd1, hd2 = split_chromosome(chromo)\n",
    "\n",
    "    alpha = alpha_value(lr) #convert the integer array to the float value\n",
    "    act_func = int_af[binary_to_decimal(af)] #get the activation function string using the map\n",
    "    h1 = binary_to_decimal(hd1) #number of hidden neurons layer 1\n",
    "    h2 = binary_to_decimal(hd2) #number of hidden neurons layer 2\n",
    "\n",
    "    #Construct the model\n",
    "    model = Sequential()\n",
    "\n",
    "    #first hidden layer\n",
    "    model.add(Dense(h1, input_shape = (input_shape[1],), activation = act_func, kernel_initializer = glorot_uniform(seed = 0)))\n",
    "\n",
    "    #second hidden layer\n",
    "    model.add(Dense(h2, activation = act_func, kernel_initializer = glorot_uniform(seed = 0)))\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(classes, activation = 'sigmoid'))\n",
    "    \n",
    "    #Optimizer used for the training\n",
    "    opt = keras.optimizers.Adam(learning_rate=alpha)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\n",
    "    #call the fit method to perform the training. Store the history used to get the lossesx\n",
    "    history = model.fit(x = X, y = Y, epochs = num_epochs, verbose = 0)\n",
    "    losses = history.history['loss']\n",
    "\n",
    "    #return the mean loss\n",
    "    return np.mean(losses)\n",
    "\n",
    "# Train_model([0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm #for the progress bar\n",
    "\n",
    "# --------------------------- MAIN FUNCTION ---------------------------------\n",
    "#This function is responsible to handle the entire algorithm. It takes as arguments the population size, chromosome size and the number of generations or number of epochs and returns the minimum loss or maximum fitness for each generation or population.\n",
    "\n",
    "def main(pop_size, chromo_size, num_gen):\n",
    "    #generate the initial population\n",
    "    pop = Initial_Population(pop_size, chromo_size)\n",
    "\n",
    "    #stores the losses for entire generation\n",
    "    losses = [float() for i in range(pop_size)]\n",
    "\n",
    "    #stores the fitness for entire generation\n",
    "    fitness = [float() for i in range(pop_size)]\n",
    "\n",
    "    #run a loop for the number of generations\n",
    "    for i in range(num_gen):\n",
    "        title = \"Generation {} Progress\".format(i + 1)\n",
    "\n",
    "        # Train the model for different generations and the metric for fitness is the loss. Lower the loss, higher the fitness\n",
    "        for j in tqdm(range(pop_size), title, ncols = 100):\n",
    "            losses[j] = Train_model(pop[j])\n",
    "\n",
    "            #fitness is the inverse of the loss.\n",
    "            fitness[j] = 1.0/losses[j]\n",
    "        \n",
    "             \n",
    "    \n",
    "main(pop_size, chromo_size, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}