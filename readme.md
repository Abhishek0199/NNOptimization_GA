# Neural Network Architecture Optimization using Genetic Algorithms:

### About:

The following code implements Genetic Algorithm for the optimization of neural network architecture which includes learning rate, activation functions and number of hidden neurons with fixed 1 or 2 hidden layers and output activation function as sigmoid because of binary classification. The training for each neural network will be done using Keras python library.
The chromosome is defined as:

- Alpha (Learning Rate) -> 4 bits
  - Constraints are: > 0 and < 1
  - The value of alpha is calculated by get the decimal value as though the bits were after decimal i.e. if alpha is represented as - 0010 -> (1/2^3)*0 + (1/2^4)*0 + (1/2^5)*1 + (1/2^6)*0. This is done to keep the value of alpha small.
- Activation Functions -> 2 bits for 4 AF:
  - Relu = 0
  - Tanh = 1
  - Sigmoid = 2
  - Selu = 3
- Number of neurons in hidden layer 1 (5 bits)
  - Constraints are: >=2
- Number of neurons in hidden layer 2 (5 bits)
  - No Constraints can be from 0 to max value
- Output AF -> Sigmoid (binary classification)
- The population size = 30
- The chromosome size = 4 + 2 + 5 + 5 = 16
- Number of epochs for each training is 20
- We are using the same activation function for both the hidden layers and the input layer.

_Please Note - For performing any step, ensure that the chromsomes are valid chromosomes (i.e. satisfy all the constraints)_

### Generation of Initial Population:

The chromosome is taken to be an integer array where each bit or value is a separate gene. For the generation of the initial population we will generate each parameter of the neural network is generated bit-wise. This is done by tossing a coin or generating a random number between 0 and 1, and then if it is greater than 0.5 then the bit is set, else the bit is unset. Also, we keep track of the constraints imposed on the number of hidden neurons.

### Training of the Population:

After the generation of the population we now need to train the model generated by the chromosome. For training, I have used Keras inbuilt libraries to construct the model from the component values and train it on the dataset. It finally returns the losses for that particular generation. These losses are then used to perform further processes.

### Elitism:

To maintain the existence of the "Good Population" (having high fitness), we will add the top N individuals into the new population without making any modifications.

### Selection:

The process of the selection of two parents is done using _Roulette Wheel Selection_. For performing this:

- We will first convert the loss obtained from each chromosome after training based on the model described by it into the fitness, which is the inverse of the loss (i.e. higher the loss, lower the fitness).
- Assign area to each individual in the roulette wheel.
- Select two distinct parents, which are then used to perform crossover.

### Crossover:

After the selection of two parents, we now proceed on the step of performing crossover or exchange of their genetic material. For crossover, we are using _Two-Point Crossover_ done as follows:

- Generation two random crossover points or indices.
- Swap the material of both the parents present in alternate blocks.
- Keep the remaining material same.
- Return the two offsprings.

### Mutation:

The final step before the generation of the new population is mutation. This is done in order to improve the _Diversity_ of a generation. For performing mutation:

- Consider each chromosome generated using crossover (do not take the chromosomes generated due to elitism).
- For each gene of the chromosome, generate a random number between 0 and 1.
- If the r.n. is less than the mutation rate, then replace the gene by a random value 0 or 1.
- Return the newly generated chromosome.
